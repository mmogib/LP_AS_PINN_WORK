{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\u001b[35m+--------+-------------------------------------------------------------------------+\n",
      "| t      | ŷ(t)                                                                    |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|   0.00 | [ 0.  0.  0.  0. -0.  0.  0. -0.]                                       |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|   2.50 | [-0.51622915  1.6665292   1.7863696   0.6442201   0.75406796  1.0715411 |\n",
      "|        |  -0.00254623 -0.00289825]                                               |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|   5.00 | [-0.3519519   1.5629302   1.6229733   0.9386521   1.0295663   1.7156954 |\n",
      "|        |  -0.00424191  0.00363769]                                               |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|   7.50 | [-0.21428967  1.4687133   1.5892721   0.9820743   1.0705788   1.9831713 |\n",
      "|        |   0.00201018 -0.00400594]                                               |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|  10.00 | [-1.20068185e-01  1.39508772e+00  1.57333958e+00  9.83713984e-01        |\n",
      "|        |   1.07899427e+00  2.13647580e+00  5.58944745e-03  1.69881165e-03]       |\n",
      "+--------+-------------------------------------------------------------------------+\n",
      "|  10.20 | [-0.11376932  1.3895389   1.5716316   0.9833279   1.0792458   2.1465456 |\n",
      "|        |   0.00555089  0.00266559]                                               |\n",
      "+--------+-------------------------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from colorama import Fore, Style\n",
    "from prettytable import PrettyTable, ALL\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# DEVICE (inlined from device.py)\n",
    "# ------------------------------\n",
    "def get_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# MODEL and HELPER FUNCTIONS (inlined from models.py)\n",
    "# ------------------------------\n",
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, out_vars=5):\n",
    "        super(PINN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(1, 100)\n",
    "        self.fc2 = torch.nn.Linear(100, out_vars)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.out_vars = out_vars\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Forward pass for a scalar (or batch) time input.\n",
    "        We assume t is a tensor of shape (N, 1) or a scalar tensor.\n",
    "        The network output is modulated as:\n",
    "            ŷ(t) = (1 - exp(-t)) * NN(t)\n",
    "        to enforce ŷ(0) = 0.\n",
    "        \"\"\"\n",
    "        if t.dim() == 0:\n",
    "            t = t.unsqueeze(0)\n",
    "        x = self.activation(self.fc1(t))\n",
    "        out = self.fc2(x)\n",
    "        return (1 - torch.exp(-t)) * out\n",
    "\n",
    "\n",
    "def load_model(model, device, filename):\n",
    "    model.load_state_dict(torch.load(filename, map_location=device))\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model: PINN, test_times: List[int], device=torch.device(\"cpu\")):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"t\", \"ŷ(t)\"]\n",
    "    table.hrules = ALL  # horizontal line between rows\n",
    "    table.align[\"t\"] = \"l\"\n",
    "    table.align[\"ŷ(t)\"] = \"l\"\n",
    "    for t in test_times:\n",
    "        t_tensor = torch.tensor(\n",
    "            t, dtype=torch.float32, device=device, requires_grad=True\n",
    "        )\n",
    "        y_pred = model(t_tensor)\n",
    "        # Flatten the tensor and convert to string for display.\n",
    "        y_pred_str = str(y_pred.detach().cpu().numpy().flatten())\n",
    "        table.add_row([f\"{t:6.2f}\", y_pred_str])\n",
    "    print(Fore.MAGENTA + table.get_string() + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN: Reload and test the model\n",
    "# ------------------------------\n",
    "dev = get_device()\n",
    "\n",
    "# Create an instance of PINN with 8 output variables and move it to the device.\n",
    "model = PINN(out_vars=8).to(dev)\n",
    "\n",
    "# Set the filename for the saved model. Adjust as needed.\n",
    "filename = \"../pinn_1000_2025_02_20.pt\"\n",
    "\n",
    "# Reload the saved model.\n",
    "model_reloaded = load_model(model, dev, filename)\n",
    "\n",
    "# Define test times and evaluate the model.\n",
    "test_times = [0.0, 2.5, 5.0, 7.5, 10.0, 10.2]\n",
    "test_model(model_reloaded, test_times, device=dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
